{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Techniques for Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "[PyTorch Techniques for Model Optimization](#pytorch-techniques-for-model-optimization)\n",
    "\n",
    "- [Saving Progress w/ Model Checkpointing](##saving-progress-w-model-checkpointing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Progress w/ Model Checkpointing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Checkpointing Intro.** - Will now focus on model checkpointing using PyTorch. This is vital technique in machine learning that allows save state of model during training, ensuring best-performing models are preserved. Will come to understand how implement model checkpointing, allowing to save model whenever achieves best performance on a validation set.\n",
    "\n",
    "So model checkpointing involves saving state of a neural network model at various points during training process. Crucial for several reasons:\n",
    "- **Prevent Loss of Progress**: In case of unexpected interruptions (e.g., power failure, hardware consumption), checkpointing helps resuming training from last saved state.\n",
    "- **Save Best Performing Models**: By saving model whenever achieves a new best performance on validation set, ensure that retain best version of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting up Environment** - Assume set up environment seen before and used below: import necessary libraries, do preprocessing of Wine dataset, define model, define loss and optimizer. Will for now omit training loop with eval, graphing of loss and finally saving model loading and confirming same val_loss, as this code will be modified with checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.utils as skUtils\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "wine_set: skUtils.Bunch = load_wine()\n",
    "\n",
    "def load_preprocessed_data(wine: skUtils.Bunch) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    X: np.ndarray = wine.data\n",
    "    y: np.ndarray = wine.target\n",
    "\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "\n",
    "    scaler: StandardScaler = StandardScaler().fit(Xtrain)\n",
    "    Xtrain_scaled: np.ndarray = scaler.transform(Xtrain)\n",
    "    Xtest_scaled: np.ndarray = scaler.transform(Xtest)\n",
    "\n",
    "    Xtrain_tensor: torch.Tensor = torch.tensor(Xtrain_scaled, dtype=torch.float32)\n",
    "    Xtest_tensor: torch.Tensor = torch.tensor(Xtest_scaled, dtype=torch.float32)\n",
    "    ytrain_tensor: torch.Tensor = torch.tensor(ytrain, dtype=torch.long)\n",
    "    ytest_tensor: torch.Tensor = torch.tensor(ytest, dtype=torch.long)\n",
    "\n",
    "    return Xtrain_tensor, Xtest_tensor, ytrain_tensor, ytest_tensor\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_data(wine_set)\n",
    "\n",
    "model: nn.Sequential = nn.Sequential( # MAKE SURE YOU CAN CUSTOM DEFINE TOO!!\n",
    "    nn.Linear(in_features=13, out_features=10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 3)\n",
    ")\n",
    "\n",
    "criterion: nn.CrossEntropyLoss = nn.CrossEntropyLoss()\n",
    "optimizer: optim.Adam = optim.Adam(model.parameters(), lr=0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
