{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Techniques for Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "[PyTorch Techniques for Model Optimization](#pytorch-techniques-for-model-optimization)\n",
    "\n",
    "- [Model Checkpointing Intro.](##model-checkpointing-intro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Checkpointing Intro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will now focus on model checkpointing using PyTorch. This is vital technique in machine learning that allows save state of model during training, ensuring best-performing models are preserved. Will come to understand how implement model checkpointing, allowing to save model whenever achieves best performance on a validation set.\n",
    "\n",
    "So model checkpointing involves saving state of a neural network model at various points during training process. Crucial for several reasons:\n",
    "- **Prevent Loss of Progress**: In case of unexpected interruptions (e.g., power failure, hardware consumption), checkpointing helps resuming training from last saved state.\n",
    "- **Save Best Performing Models**: By saving model whenever achieves a new best performance on validation set, ensure that retain best version of our model.\n",
    "\n",
    "Assume have set up environment seen before: import necessary libraries, do preprocessing of Wine dataset, define model, define loss and optimizer, training loop with eval, graphing of loss and finally saving model loading and confirming same val_loss."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
